


import pickle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

def load_data(file_path):
    """
    Carrega os dados de um arquivo pickle
    """
    with open(file_path, 'rb') as f:
        data = pickle.load(f)
    return data

def flatten_data(data):
    """
    Transforma os dados hierarquicos em um dataframe plano
    """
    flattened_data = []
    for syndrome_id, subjects in data.items():
        for subject_id, images in subjects.items():
            for image_id, embedding in images.items():
                flattened_data.append({
                    "syndrome_id": syndrome_id,
                    "subject_id": subject_id,
                    "image_id": image_id,
                    "embedding": embedding
                })
    return pd.DataFrame(flattened_data)

def validate_embeddings(df):
    """
    Verifica a integridade dos embeddings e remove entradas inconsistentes
    """
    # Verifica se todos os embeddings tem 320 dimensões
    df['embedding_length'] = df['embedding'].apply(lambda x: len(x))
    inconsistent_embeddings = df[df['embedding_length'] != 320]
    if not inconsistent_embeddings.empty:
        print("Inconsistências detectadas nos embeddings:")
        print(inconsistent_embeddings)
        # Remover embeddings inconsistentes
        df = df[df['embedding_length'] == 320]
    df.drop(columns=['embedding_length'], inplace=True)
    return df

def check_data_integrity(df):
    """
    Exibe informações gerais e verifica dados ausentes
    """
    print("Informações gerais do DataFrame:")
    print(df.info())
    print("\nVerificando valores ausentes:")
    print(df.isnull().sum())
    print("\nExemplo de dados:")
    print(df.head())

def embedding_statistics(df):
    """
    Calcula estatisticas e exibe a distribuicao dos valores nos embeddings
    """
    embeddings_array = np.array(df['embedding'].tolist())
    print("Estatísticas gerais dos embeddings:")
    print("Média:", np.mean(embeddings_array))
    print("Desvio padrão:", np.std(embeddings_array))
    print("Min:", np.min(embeddings_array))
    print("Max:", np.max(embeddings_array))

    # Visualização
    plt.figure(figsize=(10, 6))
    plt.hist(embeddings_array.flatten(), bins=50, alpha=0.7)
    plt.title('Distribuição de Valores nos Embeddings')
    plt.xlabel('Valor')
    plt.ylabel('Frequência')
    plt.savefig('embedding_statistics.png', dpi=300, bbox_inches='tight')
    plt.show()

def exploratory_data_analysis(df):
    """
    Realiza análise exploratória basica dos dados
    """
    print("Número total de imagens:", len(df))
    print("Número total de síndromes únicas:", df['syndrome_id'].nunique())
    
    syndrome_counts = df['syndrome_id'].value_counts()
    print("\nDistribuição de imagens por síndrome:")
    print(syndrome_counts)
    
    # Visualização
    plt.figure(figsize=(10, 6))
    syndrome_counts.plot(kind='bar')
    plt.title('Distribuição de Imagens por Síndrome')
    plt.xlabel('Síndrome ID')
    plt.ylabel('Quantidade de Imagens')
    plt.savefig('exploratory_data_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

file_path = 'mini_gm_public_v0.1.p'

data = load_data(file_path)
df = flatten_data(data)
df = validate_embeddings(df)


print(df.head())


check_data_integrity(df)





embedding_statistics(df)





exploratory_data_analysis(df)








from sklearn.manifold import TSNE
import seaborn as sns

def visualize_embeddings_tsne(df, perplexity=30, learning_rate=200, random_state=42):
    """
    Reduz a dimensionalidade dos embeddings para 2D usando t-SNE e visualiza os resultados
    """
    # Extrai os embeddings e os rotulos
    embeddings = np.array(df['embedding'].tolist())
    syndrome_ids = df['syndrome_id']

    # Aplica tSNE
    tsne = TSNE(n_components=2, perplexity=perplexity, learning_rate=learning_rate, random_state=random_state)
    embeddings_2d = tsne.fit_transform(embeddings)

    # Cria um dataframe para os resultados 
    tsne_df = pd.DataFrame({
        'Dimension 1': embeddings_2d[:, 0],
        'Dimension 2': embeddings_2d[:, 1],
        'Syndrome ID': syndrome_ids
    })

    # Visualiza 
    plt.figure(figsize=(10, 8))
    sns.scatterplot(
        data=tsne_df,
        x='Dimension 1',
        y='Dimension 2',
        hue='Syndrome ID',
        palette='tab10',
        s=50,
        alpha=0.7
    )
    plt.title('Visualização t-SNE dos Embeddings por Síndrome ID')
    plt.xlabel('Dimensão 1')
    plt.ylabel('Dimensão 2')
    plt.legend(loc='best', title='Síndrome ID', bbox_to_anchor=(1.05, 1), borderaxespad=0.)
    plt.tight_layout()
    plt.savefig('visualize_embeddings_tsne.png', dpi=300, bbox_inches='tight')
    plt.show()

visualize_embeddings_tsne(df)








from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, top_k_accuracy_score
from sklearn.neighbors import KNeighborsClassifier
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

def evaluate_model(y_true, y_pred, y_prob, k):
    """
    Avalia o desempenho do modelo com base em diferentes metricas
    """
    auc = roc_auc_score(y_true, y_prob, multi_class='ovr')
    f1 = f1_score(y_true, y_pred, average='weighted')
    top_k_acc = top_k_accuracy_score(y_true, y_prob, k=k)
    return auc, f1, top_k_acc

def knn_classification(df, k_values=range(1, 16), metric='euclidean'):
    """
    Realiza classificacao KNN com validação cruzada e retorna métricas de desempenho
    """
    embeddings = np.array(df['embedding'].tolist())
    labels = df['syndrome_id']
    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

    results = {k: {"AUC": [], "F1-Score": [], "Top-1 Accuracy": []} for k in k_values}

    for train_index, test_index in skf.split(embeddings, labels):
        X_train, X_test = embeddings[train_index], embeddings[test_index]
        y_train, y_test = labels.iloc[train_index], labels.iloc[test_index]
        
        for k in k_values:
            # Define KNN
            knn = KNeighborsClassifier(n_neighbors=k, metric=metric)
            knn.fit(X_train, y_train)
            
            # Predicoes
            y_pred = knn.predict(X_test)
            y_prob = knn.predict_proba(X_test)
            
            # Avaliacao do modelo
            auc, f1, top_k_acc = evaluate_model(y_test, y_pred, y_prob, k=1)
            results[k]["AUC"].append(auc)
            results[k]["F1-Score"].append(f1)
            results[k]["Top-1 Accuracy"].append(top_k_acc)

    # Agrega resultados
    aggregated_results = {k: {metric: np.mean(values[metric]) for metric in values} for k, values in results.items()}
    return aggregated_results

def compare_metrics(df, k_values=range(1, 16)):
    """
    Compara as metricas de classificacao para as distâncias Euclidean e Cosine
    """
    print("Calculando para Métrica Euclidean...")
    results_euclidean = knn_classification(df, k_values=k_values, metric='euclidean')
    
    print("Calculando para Métrica Cosine...")
    results_cosine = knn_classification(df, k_values=k_values, metric='cosine')

    return results_euclidean, results_cosine

k_values = range(1, 16)
results_euclidean, results_cosine = compare_metrics(df, k_values=k_values)

euclidean_df = pd.DataFrame(results_euclidean).T
cosine_df = pd.DataFrame(results_cosine).T

print("\nResultados - Métrica Euclidean")
print(euclidean_df)

print("\nResultados - Métrica Cosine")
print(cosine_df)

# Visualizacao
def plot_results(results, title):
    """
    Plota os resultados das metricas para diferentes valores de k
    """
    ks = list(results.keys())
    auc = [results[k]["AUC"] for k in ks]
    f1 = [results[k]["F1-Score"] for k in ks]
    top1 = [results[k]["Top-1 Accuracy"] for k in ks]

    plt.figure(figsize=(10, 6))
    plt.plot(ks, auc, label="AUC")
    plt.plot(ks, f1, label="F1-Score")
    plt.plot(ks, top1, label="Top-1 Accuracy")
    plt.title(title)
    plt.xlabel("Número de Vizinhos (k)")
    plt.ylabel("Métrica")
    plt.legend()
    plt.grid()
    plt.savefig('plot_results_' + title + '.png', dpi=300, bbox_inches='tight')
    plt.show()

plot_results(results_euclidean, "Desempenho-Métrica_Euclidean")

plot_results(results_cosine, "Desempenho-Métrica_Cosine")








from sklearn.metrics import roc_curve, auc

def plot_roc_curves(df, k, metric, ax):
    """
    Calcula e plota a curva ROC AUC media para a metrica especificada
    """
    embeddings = np.array(df['embedding'].tolist())
    labels = pd.get_dummies(df['syndrome_id']).values  
    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

    mean_fpr = np.linspace(0, 1, 100)
    tprs = []
    aucs = []

    for train_index, test_index in skf.split(embeddings, df['syndrome_id']):
        X_train, X_test = embeddings[train_index], embeddings[test_index]
        y_train, y_test = labels[train_index], labels[test_index]

        knn = KNeighborsClassifier(n_neighbors=k, metric=metric)
        knn.fit(X_train, np.argmax(y_train, axis=1))
        y_prob = knn.predict_proba(X_test)

        # Curvas ROC para cada classe
        for i in range(y_test.shape[1]):
            fpr, tpr, _ = roc_curve(y_test[:, i], y_prob[:, i])
            interp_tpr = np.interp(mean_fpr, fpr, tpr)
            interp_tpr[0] = 0.0
            tprs.append(interp_tpr)
            roc_auc = auc(fpr, tpr)
            aucs.append(roc_auc)

    # Media e intervalo da curva ROC
    mean_tpr = np.mean(tprs, axis=0)
    mean_tpr[-1] = 1.0
    mean_auc = auc(mean_fpr, mean_tpr)

    # Plotagem
    ax.plot(mean_fpr, mean_tpr, label=f'{metric.capitalize()} (AUC = {mean_auc:.2f})')
    ax.fill_between(
        mean_fpr,
        np.maximum(mean_tpr - np.std(tprs, axis=0), 0),
        np.minimum(mean_tpr + np.std(tprs, axis=0), 1),
        alpha=0.2,
    )
    return mean_auc

# Plotando as curvas para Cosine e Euclidean
fig, ax = plt.subplots(figsize=(10, 6))
auc_euclidean = plot_roc_curves(df, k=5, metric='euclidean', ax=ax)
auc_cosine = plot_roc_curves(df, k=5, metric='cosine', ax=ax)

# Configuracao do gráfico
ax.plot([0, 1], [0, 1], 'k--', lw=2)
ax.set_title('Curvas ROC AUC Médias - Euclidean vs Cosine')
ax.set_xlabel('Taxa de Falsos Positivos (FPR)')
ax.set_ylabel('Taxa de Verdadeiros Positivos (TPR)')
ax.legend()
plt.grid()
plt.tight_layout()
plt.savefig('plot_roc_curves.png', dpi=300, bbox_inches='tight')
plt.show()

print("\nTabela de Resultados - Métrica Euclidean")
print(euclidean_df)

print("\nTabela de Resultados - Métrica Cosine")
print(cosine_df)












